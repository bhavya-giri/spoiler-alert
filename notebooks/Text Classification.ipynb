{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948c8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer,Trainer, TrainingArguments,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640220f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78023</td>\n",
       "      <td>Greatest Jeff Bridges movie ever. I absolutely...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419388</td>\n",
       "      <td>Rarely, very rarely, I give such high rating o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>557333</td>\n",
       "      <td>I must say, dang, I underrated this film immen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>451866</td>\n",
       "      <td>If I ever got together with a group of my frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190239</td>\n",
       "      <td>In theory, a thriller about magic should be a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0       78023  Greatest Jeff Bridges movie ever. I absolutely...      0\n",
       "1      419388  Rarely, very rarely, I give such high rating o...      0\n",
       "2      557333  I must say, dang, I underrated this film immen...      0\n",
       "3      451866  If I ever got together with a group of my frie...      0\n",
       "4      190239  In theory, a thriller about magic should be a ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "valid_df = pd.read_csv(\"../data/valid.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fbad01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts(ascending=True).plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43361bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"Words Per Review\"] = train_df[\"text\"].str.split().apply(len)\n",
    "train_df.boxplot(\"Words Per Review\", by=\"label\", grid=False, showfliers=False,\n",
    "           color=\"gray\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e069bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Words Per Review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0533c56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['Unnamed: 0', 'text', 'label'],\n",
       "     num_rows: 22956\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['Unnamed: 0', 'text', 'label'],\n",
       "     num_rows: 5740\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "train_ds,valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e53763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc7b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 19065, 990, 2321, 18765, 1569, 655, 4, 38, 3668, 2638, 42, 822, 4, 85, 34, 960, 35, 9117, 6, 2196, 6, 39428, 6, 627, 2543, 6, 642, 4244, 6, 14271, 1527, 6, 18257, 368, 6, 463, 10, 372, 2471, 4, 10385, 357, 87, 10, 29673, 54, 22841, 19, 39, 132, 22650, 964, 6, 65, 54, 393, 25245, 8, 5, 97, 54, 16, 10, 5490, 29011, 54, 16, 44171, 19327, 47, 9, 39, 676, 4, 509, 3579, 28862, 2012, 160, 5, 37, 661, 9, 2535, 4, 178, 20, 42127, 16, 4889, 11, 5, 1692, 9, 70, 9, 24, 4, 91, 18, 2468, 11, 358, 2698, 150, 667, 7, 1955, 66, 54, 15762, 5, 1141, 9, 10, 31541, 54, 2594, 7, 33, 5, 276, 766, 6, 2321, 1063, 428, 7897, 4, 11329, 19649, 88, 42, 822, 32, 1859, 234, 2617, 1952, 6697, 170, 28305, 11, 234, 5434, 154, 6, 574, 3209, 7897, 42078, 238, 29488, 44581, 12343, 2400, 2696, 6, 8, 10, 7323, 1371, 1238, 9, 32310, 10990, 4, 2032, 19649, 88, 5, 3344, 32, 10, 6900, 9, 372, 5422, 14, 189, 45, 146, 1472, 114, 38, 1381, 7, 3922, 734, 2527, 40386, 734, 500, 1342, 42, 1569, 25, 1010, 25, 47, 64, 16506, 1405, 301, 5885, 510, 2796, 5433, 5121, 3779, 12846, 12861, 301, 40, 464, 4, 1308, 301, 40, 464, 4, 20, 42127, 129, 1072, 39, 28862, 124, 4, 11932, 16506, 14279, 32376, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer(train_df[\"text\"][0])\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c36c803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b1b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x2a4044040> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded = train_ds.map(tokenize, batched=True, batch_size=1024)\n",
    "valid_encoded = valid_ds.map(tokenize, batched=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672d6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 22956\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad96a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "num_labels = 2\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a32dfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d655107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c61d40e8c44d5b1b63420e61ed533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f991fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "logging_steps = len(train_encoded) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-imdb-spoilers\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=3,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True, \n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ca25cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavyagiri/Developer/spoiler-alert/notebooks/roberta-base-finetuned-imdb-spoilers is already a clone of https://huggingface.co/bhavyagiri/roberta-base-finetuned-imdb-spoilers. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavyagiri/mambaforge/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 16.73 GB, other allocations: 1.31 GB, max allowed: 18.13 GB). Tried to allocate 600.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39mtraining_args, \n\u001b[1;32m      2\u001b[0m                   compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      3\u001b[0m                   train_dataset\u001b[38;5;241m=\u001b[39mtrain_encoded,\n\u001b[1;32m      4\u001b[0m                   eval_dataset\u001b[38;5;241m=\u001b[39mvalid_encoded,\n\u001b[1;32m      5\u001b[0m                   tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:2654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2654\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2657\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2678\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2679\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2680\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1196\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1208\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:844\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    835\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    837\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    838\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    839\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    842\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    843\u001b[0m )\n\u001b[0;32m--> 844\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    857\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:529\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    520\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    521\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    522\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    527\u001b[0m     )\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:340\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    332\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 340\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    350\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:260\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    257\u001b[0m         relative_position_scores_key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhrd,lrd->bhlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    258\u001b[0m         attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m relative_position_scores_query \u001b[38;5;241m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 260\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_head_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 16.73 GB, other allocations: 1.31 GB, max allowed: 18.13 GB). Tried to allocate 600.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=train_encoded,\n",
    "                  eval_dataset=valid_encoded,\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f058a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds_output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = valid_encoded[\"label\"]\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
