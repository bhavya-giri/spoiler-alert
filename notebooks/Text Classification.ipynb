{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948c8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer,Trainer, TrainingArguments,AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640220f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>358108</td>\n",
       "      <td>There is sexual pornography and then there is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373777</td>\n",
       "      <td>'Just Friends' is pretty much the standard of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6579</td>\n",
       "      <td>What can i say, that hasn't been already told?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226484</td>\n",
       "      <td>The story is formulaic. The character developm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>446451</td>\n",
       "      <td>The Curious Case of Benjamin Button (2008)  W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0      358108  There is sexual pornography and then there is ...      0\n",
       "1      373777  'Just Friends' is pretty much the standard of ...      0\n",
       "2        6579  What can i say, that hasn't been already told?...      1\n",
       "3      226484  The story is formulaic. The character developm...      1\n",
       "4      446451  The Curious Case of Benjamin Button (2008)  W...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "valid_df = pd.read_csv(\"../data/valid.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fbad01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts(ascending=True).plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43361bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"Words Per Review\"] = train_df[\"text\"].str.split().apply(len)\n",
    "train_df.boxplot(\"Words Per Review\", by=\"label\", grid=False, showfliers=False,\n",
    "           color=\"gray\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e069bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Words Per Review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0533c56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['Unnamed: 0', 'text', 'label'],\n",
       "     num_rows: 91826\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['Unnamed: 0', 'text', 'label'],\n",
       "     num_rows: 22957\n",
       " }))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "train_ds,valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e53763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc7b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 970, 16, 1363, 15570, 8, 172, 89, 16, 1476, 15570, 4, 1525, 768, 9278, 2045, 23, 498, 6, 39660, 352, 6, 7, 4157, 2099, 11, 818, 70, 4620, 1712, 51, 109, 45, 2324, 42, 2157, 7, 1476, 111, 4562, 5, 94, 80, 7673, 107, 4, 4448, 128, 17497, 19220, 108, 9909, 1302, 7, 33, 478, 2115, 10, 5808, 10656, 35, 1045, 10, 1569, 59, 4845, 4634, 6060, 203, 13698, 6, 172, 109, 24, 5, 38187, 260, 169, 111, 31348, 542, 18462, 30363, 5353, 9, 1476, 6, 18744, 8, 5074, 1809, 6, 20992, 3435, 22827, 30, 5, 275, 822, 806, 5152, 1342, 6, 8, 109, 45, 905, 62, 13, 5, 1445, 1569, 4, 32735, 40182, 14, 1712, 5, 35008, 36, 243, 337, 2071, 238, 16247, 4845, 6, 24783, 4845, 7, 10, 2116, 6, 8, 15760, 4075, 123, 19, 10, 21106, 111, 24, 21, 888, 5, 8609, 54, 32, 37581, 13, 5, 744, 9, 5772, 4, 38, 218, 75, 216, 549, 4448, 21, 145, 1473, 59, 42, 6, 50, 549, 37, 16, 95, 6168, 90, 3698, 4, 38, 206, 24, 16, 10, 269, 5808, 169, 9, 442, 418, 111, 45, 129, 16, 15352, 608, 5, 1067, 311, 9326, 6, 37, 16, 67, 608, 5, 381, 25982, 487, 6, 7417, 2009, 20812, 4, 280, 18, 24, 4448, 6, 989, 117, 7326, 7587, 28426, 4, 152, 1569, 34, 1085, 7, 109, 19, 5, 5772, 11, 5, 821, 46542, 111, 42, 1569, 16, 10, 3458, 27240, 5000, 9, 20509, 8, 43739, 8, 25, 215, 24, 16, 4736, 4226, 4, 125, 172, 456, 6, 12196, 5, 7105, 6, 4448, 3311, 7, 146, 10, 13016, 15, 42, 4, 11468, 4448, 6, 1990, 110, 220, 3458, 3951, 1496, 6, 596, 45, 1394, 31062, 255, 6166, 927, 1696, 7, 15658, 10, 865, 116, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer(train_df[\"text\"][0])\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36c803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b1b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x2ca1753f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb300e2a802478fac4a0331d1799fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded = train_ds.map(tokenize, batched=True, batch_size=1024)\n",
    "valid_encoded = valid_ds.map(tokenize, batched=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672d6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 91826\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb9d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad96a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 2\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a32dfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d655107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95074f16f8994de08664d5ba2638fe28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f991fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "logging_steps = len(train_encoded) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-imdb-spoilers\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True, \n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06ca25cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='11480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    2/11480 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 13.06 GB, other allocations: 4.91 GB, max allowed: 18.13 GB). Tried to allocate 192.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39mtraining_args, \n\u001b[1;32m      2\u001b[0m                   compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      3\u001b[0m                   train_dataset\u001b[38;5;241m=\u001b[39mtrain_encoded,\n\u001b[1;32m      4\u001b[0m                   eval_dataset\u001b[38;5;241m=\u001b[39mvalid_encoded,\n\u001b[1;32m      5\u001b[0m                   tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1837\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1840\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1843\u001b[0m ):\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:2682\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2682\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2685\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/trainer.py:2707\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2706\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2707\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1196\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1208\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:844\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    835\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    837\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    838\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    839\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    842\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    843\u001b[0m )\n\u001b[0;32m--> 844\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    857\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:529\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    520\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    521\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    522\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    527\u001b[0m     )\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:340\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    332\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 340\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    350\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:270\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    266\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 13.06 GB, other allocations: 4.91 GB, max allowed: 18.13 GB). Tried to allocate 192.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=train_encoded,\n",
    "                  eval_dataset=valid_encoded,\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2042a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds_output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
